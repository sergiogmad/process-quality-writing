{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59291,"databundleVersionId":6678907,"sourceType":"competition"}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\nfrom pathlib import Path\nimport pickle\nimport warnings\nwarnings.simplefilter(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:26:09.967651Z","iopub.execute_input":"2023-12-13T18:26:09.968105Z","iopub.status.idle":"2023-12-13T18:26:10.385081Z","shell.execute_reply.started":"2023-12-13T18:26:09.968065Z","shell.execute_reply":"2023-12-13T18:26:10.383143Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"path = Path('../input/linking-writing-processes-to-writing-quality')","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:26:10.387647Z","iopub.execute_input":"2023-12-13T18:26:10.388588Z","iopub.status.idle":"2023-12-13T18:26:10.394644Z","shell.execute_reply.started":"2023-12-13T18:26:10.388546Z","shell.execute_reply":"2023-12-13T18:26:10.392906Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Production Rate","metadata":{}},{"cell_type":"code","source":"train_logs = pd.read_csv(path/'train_logs.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:26:10.396687Z","iopub.execute_input":"2023-12-13T18:26:10.397833Z","iopub.status.idle":"2023-12-13T18:26:22.089584Z","shell.execute_reply.started":"2023-12-13T18:26:10.397791Z","shell.execute_reply":"2023-12-13T18:26:22.087087Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_logs.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:26:22.092828Z","iopub.execute_input":"2023-12-13T18:26:22.093385Z","iopub.status.idle":"2023-12-13T18:26:22.122218Z","shell.execute_reply.started":"2023-12-13T18:26:22.093343Z","shell.execute_reply":"2023-12-13T18:26:22.120738Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         id  event_id  down_time  up_time  action_time       activity  \\\n0  001519c8         1       4526     4557           31  Nonproduction   \n1  001519c8         2       4558     4962          404  Nonproduction   \n2  001519c8         3     106571   106571            0  Nonproduction   \n3  001519c8         4     106686   106777           91          Input   \n4  001519c8         5     107196   107323          127          Input   \n\n  down_event   up_event text_change  cursor_position  word_count  \n0  Leftclick  Leftclick    NoChange                0           0  \n1  Leftclick  Leftclick    NoChange                0           0  \n2      Shift      Shift    NoChange                0           0  \n3          q          q           q                1           1  \n4          q          q           q                2           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id</th>\n      <th>down_time</th>\n      <th>up_time</th>\n      <th>action_time</th>\n      <th>activity</th>\n      <th>down_event</th>\n      <th>up_event</th>\n      <th>text_change</th>\n      <th>cursor_position</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001519c8</td>\n      <td>1</td>\n      <td>4526</td>\n      <td>4557</td>\n      <td>31</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001519c8</td>\n      <td>2</td>\n      <td>4558</td>\n      <td>4962</td>\n      <td>404</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001519c8</td>\n      <td>3</td>\n      <td>106571</td>\n      <td>106571</td>\n      <td>0</td>\n      <td>Nonproduction</td>\n      <td>Shift</td>\n      <td>Shift</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001519c8</td>\n      <td>4</td>\n      <td>106686</td>\n      <td>106777</td>\n      <td>91</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001519c8</td>\n      <td>5</td>\n      <td>107196</td>\n      <td>107323</td>\n      <td>127</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Production Rate","metadata":{}},{"cell_type":"code","source":"# chars_product = input_char - remove_cut_chars - first_strings_replace_chars + second_strings_replace_chars + paste_chars\nid_groups = train_logs.groupby('id')\n\ntrain_logs['input_chars_aux'] = id_groups['activity'].transform(lambda x: (x == 'Input').sum())\n    \ntrain_logs['remove_cut_chars_aux'] = id_groups['activity'].transform(\n    lambda x: (train_logs.loc[x.index, 'text_change'][x == 'Remove/Cut']).str.len().sum()\n    )\n\ntrain_logs['paste_chars_aux'] = id_groups['activity'].transform(\n    lambda x: (train_logs.loc[x.index, 'text_change'][x == 'Paste']).str.len().sum()\n    )\n\ntrain_logs['total_time_mins'] = np.round(id_groups['up_time'].transform(\n    lambda x: x.iloc[-1] / 60000), 1)\n\nfor _, group in id_groups:\n    first_strings_replace_chars = 0\n    second_strings_replace_chars = 0\n    \n    for replace_str in group[group.activity == \"Replace\"].text_change.values:\n        arrow_idx = replace_str.find(' => ')\n        first_strings_replace_chars += arrow_idx\n        len_second_str = len(replace_str) - arrow_idx - len(' => ')\n        second_strings_replace_chars += len_second_str\n    \n    # Assign accumulated values to the corresponding columns for the group\n    train_logs.loc[group.index, 'first_strings_replace_chars_aux'] = first_strings_replace_chars\n    train_logs.loc[group.index, 'second_strings_replace_chars_aux'] = second_strings_replace_chars\n    \n# chars_product = input_chars - remove_cut_chars - first_strings_replace_chars + second_strings_replace_chars + paste_chars\ntrain_logs['chars_product'] = train_logs.input_chars_aux - train_logs.remove_cut_chars_aux - \\\n        train_logs.first_strings_replace_chars_aux + train_logs.second_strings_replace_chars_aux + train_logs.paste_chars_aux\n\ntrain_logs['chars_per_min_product'] = np.round(train_logs.chars_product / train_logs.total_time_mins, 1)\n\n# chars_process\ntrain_logs['chars_process'] = train_logs.input_chars_aux + train_logs.second_strings_replace_chars_aux +\\\n                              train_logs.paste_chars_aux\ntrain_logs['chars_per_min_process'] = np.round(train_logs.chars_process / train_logs.total_time_mins, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:26:22.123422Z","iopub.execute_input":"2023-12-13T18:26:22.123762Z","iopub.status.idle":"2023-12-13T18:26:39.025981Z","shell.execute_reply.started":"2023-12-13T18:26:22.123731Z","shell.execute_reply":"2023-12-13T18:26:39.023823Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# words_per_min_product\ntrain_logs['last_word_count_aux'] = id_groups['word_count'].transform(lambda x: x.values[-1])\ntrain_logs['words_per_min_product'] = np.round(train_logs.last_word_count_aux / train_logs.total_time_mins, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:26:39.028022Z","iopub.execute_input":"2023-12-13T18:26:39.028415Z","iopub.status.idle":"2023-12-13T18:26:39.826967Z","shell.execute_reply.started":"2023-12-13T18:26:39.028377Z","shell.execute_reply":"2023-12-13T18:26:39.824433Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# words_per_min_process, sentences_per_min_process, sentences_per_min_product, paragraphs_per_min_process\nfor _, group in id_groups:\n    diff_word_count = group['word_count'].shift(1) - group['word_count']\n    num_deleted_words = np.maximum(0, diff_word_count).sum()\n    \n    input_sentences = group[(group['text_change'].str.contains('[\\.\\;\\?\\!\\:]', regex=True)) &\n                                (group.activity=='Input')].event_id.count()\n    \n    remove_cut_sentences = group[(group['text_change'].str.contains('[\\.\\;\\?\\!\\:]', regex=True)) &\n                                (group.activity=='Remove/Cut')].event_id.count()\n    \n    input_paragraphs = group[(group.activity=='Input') & (group.text_change.str.contains('\\n'))].event_id.count()\n        \n    # Assign accumulated values to the corresponding columns for the group\n    train_logs.loc[group.index, 'num_deleted_words_aux'] = num_deleted_words\n    train_logs.loc[group.index, 'input_sentences_aux'] = input_sentences\n    train_logs.loc[group.index, 'remove_cut_sentences_aux'] = remove_cut_sentences\n    train_logs.loc[group.index, 'input_paragraphs_aux'] = input_paragraphs\n    \nsentences_process = input_sentences\nsentences_product = input_sentences - remove_cut_sentences\nparagraphs_process = input_paragraphs\n\ntrain_logs = (\n    train_logs.assign(\n    total_words_aux=lambda x: x['last_word_count_aux'] + x['num_deleted_words_aux'],\n    words_per_min_process=lambda x: x['total_words_aux'] / x['total_time_mins'],\n    sentences_per_min_process=lambda x: x['input_sentences_aux'] / x['total_time_mins'],\n    sentences_per_min_product=lambda x: x['input_sentences_aux'] -\\\n                                                  x['remove_cut_sentences_aux'] / x['total_time_mins'],\n    paragraphs_per_min_process=lambda x: x['input_paragraphs_aux'] / x['total_time_mins']\n    )\n    .round(1)\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:26:39.829447Z","iopub.execute_input":"2023-12-13T18:26:39.829897Z","iopub.status.idle":"2023-12-13T18:27:10.622662Z","shell.execute_reply.started":"2023-12-13T18:26:39.829837Z","shell.execute_reply":"2023-12-13T18:27:10.620887Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Pause","metadata":{}},{"cell_type":"code","source":"# num_pauses, pauses_per_min, pause_time_proportion_perc, mean_pause_length\nfor _, group in id_groups:\n    iki = group['down_time'] - group['up_time'].shift(1)\n    filtered_iki = [num for num in iki if num >= 2000]\n    num_pauses = len(filtered_iki)\n    pause_time = sum(filtered_iki)\n\n    # Assign accumulated values to the corresponding columns for the group\n    train_logs.loc[group.index, 'num_pauses'] = num_pauses\n    train_logs.loc[group.index, 'pause_time_aux'] = pause_time  \n    \ntrain_logs = (\n    train_logs.assign(\n    pauses_per_min=np.round(train_logs.num_pauses / train_logs.total_time_mins, 1),\n    pause_time_proportion_perc=np.round((100 * train_logs.pause_time_aux) / (60000 * train_logs.total_time_mins), 1),\n    mean_pause_length=np.round(train_logs.pause_time_aux / train_logs.num_pauses, 1)\n    )\n    .round(1)\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:27:10.624501Z","iopub.execute_input":"2023-12-13T18:27:10.624870Z","iopub.status.idle":"2023-12-13T18:27:20.271589Z","shell.execute_reply.started":"2023-12-13T18:27:10.624822Z","shell.execute_reply":"2023-12-13T18:27:20.269800Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# mean_pause_length_btw_paragraphs\nfor _, group in id_groups:\n    enter_input_rows_idxs = group[(group.down_event == 'Enter') & (group.activity == 'Input')].index\n\n    # Filter consecutive Enter events\n    filtered_enter_rows_idx = [idx for idx in enter_input_rows_idxs if idx - 1 not in enter_input_rows_idxs]\n\n    # Look for time when previous paragraph ended and time when following paragraph started\n    pause_time_btw_paragraphs, pauses_btw_paragraphs = 0, 0\n    for idx in filtered_enter_rows_idx:\n        word_count_enter = group.at[idx, 'word_count']\n        if word_count_enter > 0:\n            slice_i = group[(group.index >= idx - 6) & (group.index <= idx - 1) & \n                                (group.activity=='Input')]\n            if not slice_i.empty:\n                initial_time = slice_i['up_time'].values[-1]\n                \n                slice_f = group[(group.index >= idx + 1) & (group.index <= idx + 6) & \n                                (group.word_count == word_count_enter + 1)]\n                if not slice_f.empty:\n                    final_time = slice_f['down_time'].values[0]\n                    pause_time_btw_paragraphs += final_time - initial_time\n                    pauses_btw_paragraphs += 1\n                 \n    # Assign accumulated values to the corresponding columns for the group\n    train_logs.loc[group.index, 'pause_time_btw_paragraphs_aux'] = pause_time_btw_paragraphs\n    if pauses_btw_paragraphs == 0:\n        train_logs.loc[group.index, 'pauses_btw_paragraphs_aux'] = np.nan\n    else:\n        train_logs.loc[group.index, 'pauses_btw_paragraphs_aux'] = pauses_btw_paragraphs\n\ntrain_logs['mean_pause_length_btw_paragraphs'] = np.round(train_logs.pause_time_btw_paragraphs_aux / \\\n                                                          train_logs.pauses_btw_paragraphs_aux, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:27:20.273336Z","iopub.execute_input":"2023-12-13T18:27:20.273739Z","iopub.status.idle":"2023-12-13T18:27:55.422039Z","shell.execute_reply.started":"2023-12-13T18:27:20.273702Z","shell.execute_reply":"2023-12-13T18:27:55.420347Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# mean_pause_length_btw_sentences\nfor _, group in id_groups:\n\n    period_rows_idxs = group[(group.text_change.str.contains('[\\.\\;\\?\\!\\:]', regex=True)) & \n                                                (group.activity == 'Input')].index\n\n    # Filter consecutive events\n    filtered_period_rows_idxs = [idx for idx in period_rows_idxs if idx - 1 not in period_rows_idxs]\n\n    # Look for time when previous sentence ended and time when following sentence started\n    pause_time_btw_sentences, pauses_btw_sentences = 0, 0\n    for idx in filtered_period_rows_idxs:\n        word_count_period = group.at[idx, 'word_count']\n        if word_count_period > 0:\n            slice_i = group[(group.index >= idx - 6) & (group.index <= idx - 1) & \n                            (group.activity=='Input') & (group.text_change=='q')]\n            if not slice_i.empty:\n                initial_time = slice_i['up_time'].values[-1]\n\n                slice_f = group[(group.index >= idx + 1) & (group.index <= idx + 6) & \n                                (group.word_count == word_count_period + 1)]\n                if not slice_f.empty:\n                    final_time = slice_f['down_time'].values[0]\n                    pause_time_btw_sentences += final_time - initial_time\n                    pauses_btw_sentences += 1\n\n    # Assign accumulated values to the corresponding columns for the group\n    train_logs.loc[group.index, 'pause_time_btw_sentences_aux'] = pause_time_btw_sentences\n    if pauses_btw_sentences == 0:\n        train_logs.loc[group.index, 'pauses_btw_sentences_aux'] = np.nan\n    else:\n        train_logs.loc[group.index, 'pauses_btw_sentences_aux'] = pauses_btw_sentences\n\ntrain_logs['mean_pause_length_btw_sentences'] = np.round(train_logs.pause_time_btw_sentences_aux / \\\n                                                         train_logs.pauses_btw_sentences_aux, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:27:55.425567Z","iopub.execute_input":"2023-12-13T18:27:55.426004Z","iopub.status.idle":"2023-12-13T18:30:43.913921Z","shell.execute_reply.started":"2023-12-13T18:27:55.425970Z","shell.execute_reply":"2023-12-13T18:30:43.912711Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# mean_pause_length_btw_words\nfor _, group in id_groups:\n\n    space_rows_idxs = group[(group.down_event=='Space') & (group.activity=='Input')].index\n\n    # Filter consecutive events\n    filtered_space_rows_idxs = [idx for idx in space_rows_idxs if idx - 1 not in space_rows_idxs]\n\n    # Look for time when previous word ended and time when following word started\n    pause_time_btw_words, pauses_btw_words = 0, 0\n    for idx in filtered_space_rows_idxs:\n        word_count_space = group.at[idx, 'word_count']\n        if word_count_space > 0:\n            slice_i = group[(group.index >= idx - 6) & (group.index <= idx - 1) & \n                            (group['activity'] == 'Input') & (group['text_change'] == 'q')]\n\n            if not slice_i.empty:\n                initial_time = slice_i['up_time'].values[-1]\n\n                slice_f = group[(group.index >= idx + 1) & (group.index <= idx + 6) & \n                                (group.word_count == word_count_space + 1)]\n                if not slice_f.empty:\n                    final_time = slice_f['down_time'].values[0]\n                    pause_time_btw_words += final_time - initial_time\n                    pauses_btw_words += 1\n\n    # Assign accumulated values to the corresponding columns for the group\n    train_logs.loc[group.index, 'pause_time_btw_words_aux'] = pause_time_btw_words\n    if pauses_btw_words == 0:\n        train_logs.loc[group.index, 'pauses_btw_words_aux'] = np.nan\n    else:\n        train_logs.loc[group.index, 'pauses_btw_words_aux'] = pauses_btw_words\n\ntrain_logs['mean_pause_length_btw_words'] = np.round(train_logs.pause_time_btw_words_aux / \\\n                                                     train_logs.pauses_btw_words_aux, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T18:30:43.915604Z","iopub.execute_input":"2023-12-13T18:30:43.916212Z","iopub.status.idle":"2023-12-13T19:19:10.723675Z","shell.execute_reply.started":"2023-12-13T18:30:43.916135Z","shell.execute_reply":"2023-12-13T19:19:10.722079Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# mean_pause_length_w_in_words\nfor _, group in id_groups:\n    group['word_count_up_aux'] = group.word_count > group.shift().word_count\n    word_count_up_idxs = group[(group.word_count_up_aux) & (group.text_change=='q')].index\n\n    # Look for time when word ended\n    pause_time_w_in_words, pauses_w_in_words = 0, 0\n    for idx in word_count_up_idxs:\n        initial_time = group.at[idx, 'up_time']\n        slice_f = group[(group.index >= idx + 1) & (group.index <= idx + 10) \n                        & (group.activity=='Input') & (group.text_change.isin(['.', ',', ';', ':', ' ', '!', '?']))] \n        if not slice_f.empty:\n            final_time = slice_f['down_time'].values[0]\n            pause_time_w_in_words += final_time - initial_time\n            pauses_w_in_words += 1\n\n    # Assign accumulated values to the corresponding columns for the group\n    train_logs.loc[group.index, 'pause_time_w_in_words_aux'] = pause_time_w_in_words\n    if pauses_w_in_words == 0:\n            train_logs.loc[group.index, 'pauses_w_in_words_aux'] = np.nan\n    else:\n        train_logs.loc[group.index, 'pauses_w_in_words_aux'] = pauses_w_in_words\n\ntrain_logs['mean_pause_length_w_in_words'] = np.round(train_logs.pause_time_w_in_words_aux / \\\n                                                      train_logs.pauses_w_in_words_aux, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:19:10.725288Z","iopub.execute_input":"2023-12-13T19:19:10.725657Z","iopub.status.idle":"2023-12-13T19:46:11.273179Z","shell.execute_reply.started":"2023-12-13T19:19:10.725612Z","shell.execute_reply":"2023-12-13T19:46:11.272074Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Revision","metadata":{}},{"cell_type":"code","source":"# deletions, deletions_per_min, mean_length_deletions, deletions_proportion_perc, \n# imm_deletions, distant_deletions, distant_deletion_ratio\nfor _, group in id_groups:\n    deletion_idxs = group[group.activity=='Remove/Cut'].index\n\n    # Filter consecutive rows\n    filtered_deletion_idxs = [idx for idx in deletion_idxs if idx - 1 not in deletion_idxs]\n\n    train_logs.loc[group.index, 'deletions'] = len(filtered_deletion_idxs)\n    train_logs.loc[group.index, 'deletions_per_min'] = np.round(len(filtered_deletion_idxs) / \\\n                                                                train_logs.total_time_mins, 1)\n    if len(filtered_deletion_idxs) == 0:\n            train_logs.loc[group.index, 'mean_length_deletions'] = np.nan\n    else:\n        train_logs.loc[group.index, 'mean_length_deletions'] = np.round(len(deletion_idxs) / len(filtered_deletion_idxs), 1)\n\n    aux_cursor_descending_row_idxs = group[group.cursor_position < \\\n                                           group.shift().cursor_position].index\n    deletions_time, distant_deletions = 0, 0\n    for idx in filtered_deletion_idxs:\n        \n        initial_time = group.at[idx, 'down_time']\n        if (group.at[idx - 1, 'activity'] == 'Nonproduction') & \\\n        (idx - 1 in aux_cursor_descending_row_idxs):\n            distant_deletions += 1\n        for i in range(idx + 1, len(group)):\n            if (i not in deletion_idxs) & (group.at[i, 'activity'] != 'Nonproduction'):\n                final_time = group.at[i - 1, 'up_time']\n                deletions_time += final_time - initial_time\n                break\n                           \n    train_logs.loc[group.index, 'deletions_time_aux'] = deletions_time\n    train_logs.loc[group.index, 'distant_deletions'] = distant_deletions\n                       \ntrain_logs = (\n    train_logs.assign(\n        deletions_proportion_perc=lambda x: 100 * x.deletions_time_aux / (60000 * x.total_time_mins),\n        imm_deletions=lambda x: x.deletions - x.distant_deletions,\n        distant_deletion_ratio=lambda x: x.distant_deletions / x.deletions\n        )\n    .round(1)\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:46:11.274656Z","iopub.execute_input":"2023-12-13T19:46:11.275032Z","iopub.status.idle":"2023-12-13T19:48:12.241457Z","shell.execute_reply.started":"2023-12-13T19:46:11.275001Z","shell.execute_reply":"2023-12-13T19:48:12.239382Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# product vs. process ratio \ntrain_logs['product_process_ratio'] = np.round(train_logs.chars_product / train_logs.chars_process, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:48:12.244091Z","iopub.execute_input":"2023-12-13T19:48:12.244483Z","iopub.status.idle":"2023-12-13T19:48:12.308992Z","shell.execute_reply.started":"2023-12-13T19:48:12.244448Z","shell.execute_reply":"2023-12-13T19:48:12.306832Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Bursts","metadata":{}},{"cell_type":"code","source":"# p_bursts, p_bursts_per_min, r_bursts, r_bursts_per_min, mean_p_bursts_chars, \n# mean_r_bursts_chars, p_bursts_proportion_perc, r_bursts_proportion_perc\nfor _, group in id_groups:\n    # Extract indices of 'Input' activities\n    input_idxs = group[group.activity == 'Input'].index\n\n    # Filter out consecutive events\n    filtered_input_idxs = [idx for idx in input_idxs if idx - 1 not in input_idxs]\n\n    # Find stretches of at least 20 consecutive input events\n    p_bursts, p_bursts_chars, pb_time, r_bursts, r_bursts_chars, rb_time = 0, 0, 0, 0, 0, 0\n\n    for idx in filtered_input_idxs[:-1]:\n        i = 0\n        # Check for consecutive 'Input' events and duration conditions\n        while (group.at[idx, 'activity'] == 'Input') and \\\n        (group.at[idx + 1, 'down_time'] - group.at[idx, 'up_time'] < 2000):\n            i += 1\n            idx += 1\n        # Update counters for bursts\n        if i >= 20:\n            if group.at[idx, 'activity'] == 'Input':\n                p_bursts += 1\n                p_bursts_chars += i\n                pb_time += group.at[idx - 1, 'up_time'] - group.at[idx - i, 'down_time']\n            else:\n                r_bursts += 1\n                r_bursts_chars += i\n                rb_time += group.at[idx - 1, 'up_time'] - group.at[idx - i, 'down_time']\n\n    # Update the corresponding columns in train_logs\n    columns_to_update = ['p_bursts', 'p_bursts_chars_aux', 'pb_time_aux', 'r_bursts', 'r_bursts_chars_aux', 'rb_time_aux']\n    train_logs.loc[group.index, columns_to_update] = p_bursts, p_bursts_chars, pb_time, r_bursts, r_bursts_chars, rb_time\n    \ntrain_logs = (\n    train_logs.assign(\n        p_bursts_per_min=lambda x: x.p_bursts / x.total_time_mins,\n        r_bursts_per_min=lambda x: x.r_bursts / x.total_time_mins,\n        mean_p_bursts_chars = lambda x: np.where(x.p_bursts != 0, x.p_bursts_chars_aux / x.p_bursts, np.nan),\n        mean_r_bursts_chars = lambda x: np.where(x.r_bursts != 0, x.r_bursts_chars_aux / x.r_bursts, np.nan),\n        p_bursts_proportion_perc=lambda x: (100 * x.pb_time_aux) / (60000 * x.total_time_mins),\n        r_bursts_proportion_perc=lambda x: (100 * x.rb_time_aux) / (60000 * x.total_time_mins)\n        )\n    .round(1)\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:48:12.311188Z","iopub.execute_input":"2023-12-13T19:48:12.311692Z","iopub.status.idle":"2023-12-13T19:50:08.783651Z","shell.execute_reply.started":"2023-12-13T19:48:12.311652Z","shell.execute_reply":"2023-12-13T19:50:08.782138Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Process Variance","metadata":{}},{"cell_type":"code","source":"# chars_proportion\ntrain_logs['time_interval_aux'] = 0\n\nfor _, group in id_groups:\n    time_intervals = pd.cut(group['up_time'], bins=10)\n    train_logs.loc[group.index, 'time_interval_aux'] = time_intervals\n    \nfor _, time_group in train_logs.groupby(['id', 'time_interval_aux']):\n    \n    input_chars_group = time_group[time_group.activity=='Input'].event_id.count()\n    \n    second_str_replace_chars_group = 0\n    for replace_str in time_group[time_group.activity==\"Replace\"].text_change.values:\n            arrow_idx = replace_str.find(' => ')\n            len_second_str = len(replace_str) - arrow_idx - len(' => ')\n            second_str_replace_chars_group += len_second_str\n    \n    paste_chars_group = len(''.join(time_group[time_group.activity=='Paste'].text_change.values))\n    chars_process_group = input_chars_group + second_str_replace_chars_group + paste_chars_group\n\n    train_logs.loc[time_group.index, 'chars_time_group_aux'] = chars_process_group\ntrain_logs['chars_proportion'] = np.round(100 * train_logs.chars_time_group_aux / train_logs.chars_process, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:50:08.786090Z","iopub.execute_input":"2023-12-13T19:50:08.786748Z","iopub.status.idle":"2023-12-13T19:51:31.550908Z","shell.execute_reply.started":"2023-12-13T19:50:08.786698Z","shell.execute_reply":"2023-12-13T19:51:31.549474Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_logs = train_logs.filter(regex='^(?!.*aux).*$')","metadata":{"execution":{"iopub.status.busy":"2023-12-13T19:51:31.552386Z","iopub.execute_input":"2023-12-13T19:51:31.552775Z","iopub.status.idle":"2023-12-13T19:51:32.791416Z","shell.execute_reply.started":"2023-12-13T19:51:31.552738Z","shell.execute_reply":"2023-12-13T19:51:32.789007Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"file_path = Path('../working/train_logs.pkl')\n\nwith open(file_path, 'wb') as file:\n        pickle.dump(train_logs, file)","metadata":{"execution":{"iopub.status.busy":"2023-12-13T20:01:31.687318Z","iopub.execute_input":"2023-12-13T20:01:31.688172Z","iopub.status.idle":"2023-12-13T20:01:39.769360Z","shell.execute_reply.started":"2023-12-13T20:01:31.688054Z","shell.execute_reply":"2023-12-13T20:01:39.765522Z"},"trusted":true},"execution_count":27,"outputs":[]}]}